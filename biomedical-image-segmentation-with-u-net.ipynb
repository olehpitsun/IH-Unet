{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2021025,"sourceType":"datasetVersion","datasetId":1209633},{"sourceId":10162989,"sourceType":"datasetVersion","datasetId":6275817}],"dockerImageVersionId":30458,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> üíâBiomedical Image Segmentation with U-Netüìà </center>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<a id=\"ToC\"></a>\n# Table of Contents\n- [1. Introduction](#1)\n- [2. Imports](#2)\n- [3. Data Loading and Preperation](#3)\n    - [3.1 Exploring data](#3.1)\n    - [3.2 Loading data](#3.2)\n- [4. EDA](#4)\n    - [4.1 Data of each class ](#4.1)\n    - [4.2 Average view of masks each class](#4.2)\n- [5. Data Pre-Processing](#5)    \n- [6. Modeling](#6)\n    - [6.1 Building U-Net Architecture](#6.1)\n    - [6.2 Training](#6.2)\n- [7. Evaluation](#7)   ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Introduction </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-datasets-images/1209633/2021025/67b9223181141133207afc36e35e3c5d/dataset-cover.jpg?t=2021-03-14-15-48-53)","metadata":{}},{"cell_type":"markdown","source":"### About Dataset\n\n* **Breast cancer** is one of the **most common** causes of death among **women worldwide**. Early detection helps in reducing the **number of early deaths**. The data reviews the **medical images of breast cancer** using ultrasound scan. **Breast Ultrasound Dataset** is categorized into **three classes** $:$ **normal, benign, and malignant images**. **Breast ultrasound images** can produce great results in **classification, detection, and segmentation** of breast cancer when combined with machine learning. \n\n* The data collected at baseline include **breast ultrasound images among women** in ages between 25 and 75 years old. This data was collected in **2018**. The number of patients is **600 female patients**. The dataset consists of **780 images** with an **average image size of 500*500 pixels**. The images are in PNG format. The ground truth images are presented with original images. The images are categorized into **three classes, which are normal, benign, and malignant**.","metadata":{}},{"cell_type":"markdown","source":"## What is U-Net?\n\n- **U-Net** is a popular deep-learning **architecture for semantic segmentation**. Originally developed for **medical images**, it had great success in this field. But, that was only the beginning! From satellite images to handwritten characters, the architecture has improved performance on a range of data types.\n- The **U-Net architecture** has been widely used in various medical image segmentation tasks, such as **brain tumor segmentation, lung segmentation, and cell segmentation**, among others.\n\n### U-Net: Convolutional Networks for Biomedical Image Segmentation\n\n![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n\n- U-net architecture (example for 32x32 pixels in the lowest resolution). Each blue box corresponds to a multi-channel feature map. The number of channels is denoted on top of the box. The x-y-size is provided at the lower left edge of the box. White boxes represent copied feature maps. The arrows denote the different operations.\n\n- This illustration is an example of Unet architecture but layers can have different size.\n\n**We apply it for breast cancer image segmentation with some modifications to the model.**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Imports </span></center></div>**","metadata":{}},{"cell_type":"code","source":"# Common\nimport tensorflow as tf\nfrom glob import glob\nimport numpy as np\n\n# Data\nfrom sklearn.model_selection import train_test_split\nimport cv2\n\n# Data visualization\nimport matplotlib.pyplot as plt\n\n# Model\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\nfrom keras.optimizers import Adam\n\n# Metrics\nfrom tensorflow.keras.metrics import *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T21:03:09.635457Z","iopub.execute_input":"2024-12-10T21:03:09.635864Z","iopub.status.idle":"2024-12-10T21:03:09.642318Z","shell.execute_reply.started":"2024-12-10T21:03:09.635833Z","shell.execute_reply":"2024-12-10T21:03:09.641112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Data Loading and Preparation </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3.1\"></a>\n## <span style=\"color:#08bf2c;\"> Exploring data : </span>","metadata":{}},{"cell_type":"code","source":"paths = glob('/kaggle/input/ihc-wunu-v1/step1/*/*')\n\nprint(f'\\033[92m')\nprint(f\"'normal' class has {len([i for i in paths if 'normal' in i and 'mask' not in i])} images and {len([i for i in paths if 'normal' in i and 'mask' in i])} masks.\")\nprint(f\"'benign' class has {len([i for i in paths if 'bening' in i and 'mask' not in i])} images and {len([i for i in paths if 'bening' in i and 'mask' in i])} masks.\")\nprint(f\"'malignant' class has {len([i for i in paths if 'malignant' in i and 'mask' not in i])} images and {len([i for i in paths if 'malignant' in i and 'mask' in i])} masks.\")\nprint(f\"\\nThere are total of {len([i for i in paths if 'mask' not in i])} images and {len([i for i in paths if 'mask' in i])} masks.\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:03:37.749507Z","iopub.execute_input":"2024-12-10T21:03:37.750519Z","iopub.status.idle":"2024-12-10T21:03:37.767700Z","shell.execute_reply.started":"2024-12-10T21:03:37.750477Z","shell.execute_reply":"2024-12-10T21:03:37.766586Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sorted(glob('/kaggle/input/ihc-wunu-v1/step1/bening/*'))[0:28]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:03:53.264624Z","iopub.execute_input":"2024-12-10T21:03:53.265833Z","iopub.status.idle":"2024-12-10T21:03:53.273975Z","shell.execute_reply.started":"2024-12-10T21:03:53.265783Z","shell.execute_reply":"2024-12-10T21:03:53.272788Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*** Some images have 2 or more masks. Combine them into one image.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"3.2\"></a>\n## <span style=\"color:#08bf2c;\"> Loading data </span>","metadata":{}},{"cell_type":"markdown","source":"Functions","metadata":{}},{"cell_type":"code","source":"def load_image(path, size):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (size,size))\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)   # shape: (size,size,3) -> (size,size,1)\n    image = image/255.   # normalize\n    return image\n\ndef load_data(root_path, size):\n    images = []\n    masks = []\n    \n    x = 0   # additional variable to identify images consisting of 2 or more masks\n    \n    for path in sorted(glob(root_path)):\n        img = load_image(path, size)   # read mask or image\n            \n        if 'mask' in path:\n            if x:   # this image has masks more than one\n                masks[-1] += img   # add the mask to the last mask\n                    \n                # When 2 masks are added, the range can increase by 0-2. So we will reduce it again to the range 0-1.\n                masks[-1] = np.array(masks[-1]>0.5, dtype='float64')\n            else:\n                masks.append(img)\n                x = 1   # if the image has a mask again, the above code will run next time\n        else:\n            images.append(img)\n            x = 0   # for moving to the next image\n    return np.array(images), np.array(masks)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:00.039069Z","iopub.execute_input":"2024-12-10T21:04:00.040070Z","iopub.status.idle":"2024-12-10T21:04:00.049737Z","shell.execute_reply.started":"2024-12-10T21:04:00.040016Z","shell.execute_reply":"2024-12-10T21:04:00.048291Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image(path, size):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (size,size))\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)   # shape: (size,size,3) -> (size,size,1)\n    image = image/255.   # normalize\n    return image\n\ndef load_data(root_path, size):\n    images = []\n    masks = []\n    \n    x = 0   # additional variable to identify images consisting of 2 or more masks\n    \n    for path in sorted(glob(root_path)):\n        img = load_image(path, size)   # read mask or image\n            \n        if 'mask' in path:\n            \n            if x:   # this image has masks more than one\n                masks[-1] += img   # add the mask to the last mask\n                    \n                # When 2 masks are added, the range can increase by 0-2. So we will reduce it again to the range 0-1.\n                masks[-1] = np.array(masks[-1]>0.5, dtype='float64')\n            else:\n                masks.append(img)\n                x = 1   # if the image has a mask again, the above code will run next time\n                print(path)\n                \n        else:\n            images.append(img)\n            x = 0   # for moving to the next image\n    return np.array(images), np.array(masks)\n    \nsize = 256   # image size: 128x128\nX, y = load_data(root_path = '/kaggle/input/ihc-wunu-v1/step1/*/*',size=size)\n\nprint(f\"X shape: {X.shape}     |  y shape: {y.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:04:09.608151Z","iopub.execute_input":"2024-12-10T21:04:09.609273Z","iopub.status.idle":"2024-12-10T21:04:10.073954Z","shell.execute_reply.started":"2024-12-10T21:04:09.609220Z","shell.execute_reply":"2024-12-10T21:04:10.072794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> EDA </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"4.1\"></a>\n## <span style=\"color:#08bf2c;\"> Data of each class </span>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(10,5))\n\n# X[0:437] benign\n# X[437:647] malignant\n# X[647:780] normal\n\ni = 10\nax[0].imshow(X[i], cmap='gray')\nax[0].set_title('Image')\nax[1].imshow(y[i], cmap='gray')\nax[1].set_title('Mask')\nax[2].imshow(X[i], cmap='gray')\nax[2].imshow(tf.squeeze(y[i]), alpha=0.5, cmap='jet')\nax[2].set_title('Union')\nfig.suptitle('Normal class', fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:15.773622Z","iopub.execute_input":"2024-12-10T21:04:15.774027Z","iopub.status.idle":"2024-12-10T21:04:16.253440Z","shell.execute_reply.started":"2024-12-10T21:04:15.773995Z","shell.execute_reply":"2024-12-10T21:04:16.252344Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(10,5))\n\ni = np.random.randint(0,14)\nax[0].imshow(X[i], cmap='gray')\nax[0].set_title('Image')\nax[1].imshow(y[i], cmap='gray')\nax[1].set_title('Mask')\nax[2].imshow(X[i], cmap='gray')\nax[2].imshow(tf.squeeze(y[i]), alpha=0.5, cmap='jet')\nax[2].set_title('Union')\nfig.suptitle('Benign class', fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:19.447925Z","iopub.execute_input":"2024-12-10T21:04:19.448775Z","iopub.status.idle":"2024-12-10T21:04:19.930803Z","shell.execute_reply.started":"2024-12-10T21:04:19.448732Z","shell.execute_reply":"2024-12-10T21:04:19.929105Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(10,5))\n\ni = np.random.randint(0,16)\nax[0].imshow(X[i], cmap='gray')\nax[0].set_title('Image')\nax[1].imshow(y[i], cmap='gray')\nax[1].set_title('Mask')\nax[2].imshow(X[i], cmap='gray')\nax[2].imshow(tf.squeeze(y[i]), alpha=0.5, cmap='jet')\nax[2].set_title('Union')\nfig.suptitle('Malignant class', fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:24.412536Z","iopub.execute_input":"2024-12-10T21:04:24.413327Z","iopub.status.idle":"2024-12-10T21:04:24.809350Z","shell.execute_reply.started":"2024-12-10T21:04:24.413288Z","shell.execute_reply":"2024-12-10T21:04:24.808029Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id=\"4.2\"></a>\n## <span style=\"color:#08bf2c;\"> Average view of masks each class </span>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(10,5))\n\nax[0].imshow(sum(y[0:16]), cmap='gray')\nax[0].set_title('Normal')\n#ax[1].imshow(sum(y[0:16]), cmap='gray')\n#ax[1].set_title('Benign')\n#ax[2].imshow(sum(y[0:0]), cmap='gray')\n#ax[2].set_title('Malignant')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:28.674821Z","iopub.execute_input":"2024-12-10T21:04:28.675258Z","iopub.status.idle":"2024-12-10T21:04:29.068692Z","shell.execute_reply.started":"2024-12-10T21:04:28.675216Z","shell.execute_reply":"2024-12-10T21:04:29.067590Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Data Pre-Processing </span></center></div>**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,3, figsize=(10,5))\n\nax[0].imshow(sum(y[0:14]), cmap='gray')\nax[0].set_title('Normal')\n#ax[1].imshow(sum(y[:437]), cmap='gray')\n#ax[1].set_title('Benign')\n#ax[2].imshow(sum(y[437:647]), cmap='gray')\n#ax[2].set_title('Malignant')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:32.090562Z","iopub.execute_input":"2024-12-10T21:04:32.091408Z","iopub.status.idle":"2024-12-10T21:04:32.481225Z","shell.execute_reply.started":"2024-12-10T21:04:32.091370Z","shell.execute_reply":"2024-12-10T21:04:32.480156Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Prepare data to modeling </span>","metadata":{}},{"cell_type":"code","source":"# drop normal class because normal class has not mask\n#X = X[:647]\n#y = y[:647]\n\nprint(f\"X shape: {X.shape}     |  y shape: {y.shape}\")\n\n# prepare data to modeling\nX = np.expand_dims(X, -1)\ny = np.expand_dims(y, -1)\n\nprint(f\"\\nX shape: {X.shape}  |  y shape: {y.shape}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:36.606335Z","iopub.execute_input":"2024-12-10T21:04:36.607120Z","iopub.status.idle":"2024-12-10T21:04:36.613274Z","shell.execute_reply.started":"2024-12-10T21:04:36.607073Z","shell.execute_reply":"2024-12-10T21:04:36.611954Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# drop normal class because normal class has not mask\n#X = X[:647]\n#y = y[:647]\n\nprint(f\"X shape: {X.shape}     |  y shape: {y.shape}\")\n\n# prepare data to modeling\nX = np.expand_dims(X, -1)\ny = np.expand_dims(y, -1)\n\nprint(f\"\\nX shape: {X.shape}  |  y shape: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:50.304983Z","iopub.execute_input":"2024-12-10T21:04:50.305790Z","iopub.status.idle":"2024-12-10T21:04:50.311635Z","shell.execute_reply.started":"2024-12-10T21:04:50.305752Z","shell.execute_reply":"2024-12-10T21:04:50.310584Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Train-test split </span>","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nprint(f'\\033[92m')\nprint('X_train shape:',X_train.shape)\nprint('y_train shape:',y_train.shape)\nprint('X_test shape:',X_test.shape)\nprint('y_test shape:',y_test.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:04:56.394040Z","iopub.execute_input":"2024-12-10T21:04:56.395036Z","iopub.status.idle":"2024-12-10T21:04:56.409692Z","shell.execute_reply.started":"2024-12-10T21:04:56.394999Z","shell.execute_reply":"2024-12-10T21:04:56.408481Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Modeling </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"6.1\"></a>\n## <span style=\"color:#08bf2c;\"> Building U-Net Architecture </span>","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Conv block </span>","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\nprint(f'\\033[92m')\nprint('X_train shape:',X_train.shape)\nprint('y_train shape:',y_train.shape)\nprint('X_test shape:',X_test.shape)\nprint('y_test shape:',y_test.shape)\n\ndef conv_block(input, num_filters):\n    conv = Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(input)\n    conv = Conv2D(num_filters, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer='he_normal')(conv)\n    return conv","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:05:07.698200Z","iopub.execute_input":"2024-12-10T21:05:07.699252Z","iopub.status.idle":"2024-12-10T21:05:07.715081Z","shell.execute_reply.started":"2024-12-10T21:05:07.699213Z","shell.execute_reply":"2024-12-10T21:05:07.713701Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Encoder block </span>","metadata":{}},{"cell_type":"code","source":"def encoder_block(input, num_filters):\n    conv = conv_block(input, num_filters)\n    pool = MaxPooling2D((2, 2))(conv)\n    return conv, pool","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:05:10.657899Z","iopub.execute_input":"2024-12-10T21:05:10.658737Z","iopub.status.idle":"2024-12-10T21:05:10.664191Z","shell.execute_reply.started":"2024-12-10T21:05:10.658699Z","shell.execute_reply":"2024-12-10T21:05:10.662807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Decoder block </span>","metadata":{}},{"cell_type":"code","source":"def decoder_block(input, skip_features, num_filters):\n    uconv = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n    con = concatenate([uconv, skip_features])\n    conv = conv_block(con, num_filters)\n    return conv","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:05:13.016187Z","iopub.execute_input":"2024-12-10T21:05:13.017035Z","iopub.status.idle":"2024-12-10T21:05:13.023255Z","shell.execute_reply.started":"2024-12-10T21:05:13.016998Z","shell.execute_reply":"2024-12-10T21:05:13.022035Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Build model </span>","metadata":{}},{"cell_type":"code","source":"def build_model(input_shape):\n    input_layer = Input(input_shape)\n    \n    s1, p1 = encoder_block(input_layer, 128)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 128)\n    \n    output_layer = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n    \n    model = Model(input_layer, output_layer, name=\"U-Net\")\n    return model\n\nmodel = build_model(input_shape=(size, size, 1))\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:05:20.995204Z","iopub.execute_input":"2024-12-10T21:05:20.995599Z","iopub.status.idle":"2024-12-10T21:05:21.309920Z","shell.execute_reply.started":"2024-12-10T21:05:20.995567Z","shell.execute_reply":"2024-12-10T21:05:21.308680Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Model plotting </span>","metadata":{}},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:05:24.066051Z","iopub.execute_input":"2024-12-10T21:05:24.066557Z","iopub.status.idle":"2024-12-10T21:05:24.576262Z","shell.execute_reply.started":"2024-12-10T21:05:24.066510Z","shell.execute_reply":"2024-12-10T21:05:24.574863Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <span style=\"color:#2981d9;\"> Model summary </span>","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:05:30.776963Z","iopub.execute_input":"2024-12-10T21:05:30.778078Z","iopub.status.idle":"2024-12-10T21:05:30.877440Z","shell.execute_reply.started":"2024-12-10T21:05:30.778034Z","shell.execute_reply":"2024-12-10T21:05:30.876395Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id=\"6.2\"></a>\n## <span style=\"color:#08bf2c;\"> Training </span>","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs = 100, validation_data = (X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-12-10T21:05:36.070346Z","iopub.execute_input":"2024-12-10T21:05:36.071211Z","iopub.status.idle":"2024-12-10T21:06:41.866180Z","shell.execute_reply.started":"2024-12-10T21:05:36.071171Z","shell.execute_reply":"2024-12-10T21:06:41.864981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(10,3))\nax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\nax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\nax[0].legend()\nax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train accuracy\")\nax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation accuracy\")\nax[1].legend()\nfig.suptitle('Loss and Accuracy', fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:06:50.709153Z","iopub.execute_input":"2024-12-10T21:06:50.710314Z","iopub.status.idle":"2024-12-10T21:06:51.060799Z","shell.execute_reply.started":"2024-12-10T21:06:50.710251Z","shell.execute_reply":"2024-12-10T21:06:51.059698Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:#5642C5;font-size:120%;font-family:Verdana;\"><center><span> Evaluation </span></center></div>**","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(5,3, figsize=(10,18))\n\nj = np.random.randint(0, X_test.shape[0], 5)\nfor i in range(5):\n    #ax[i,0].imshow(X_test[j[i]], cmap='gray')\n    #ax[i,0].set_title('Image')\n    ax[i,1].imshow(y_test[j[i]], cmap='gray')\n    ax[i,1].set_title('Mask')\n    ax[i,2].imshow(model.predict(np.expand_dims(X_test[j[i]],0),verbose=0)[0], cmap='gray')\n    ax[i,2].set_title('Prediction')\nfig.suptitle('Results', fontsize=16)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:12:55.103964Z","iopub.execute_input":"2024-12-10T21:12:55.105206Z","iopub.status.idle":"2024-12-10T21:12:56.576193Z","shell.execute_reply.started":"2024-12-10T21:12:55.105150Z","shell.execute_reply":"2024-12-10T21:12:56.574527Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'\\033[93m')\ny_pred=model.predict(X_test,verbose=0)\ny_pred_thresholded = y_pred > 0.5\n\n# mean Intersection-Over-Union metric\nIOU_keras = MeanIoU(num_classes=2)\nIOU_keras.update_state(y_pred_thresholded, y_test)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())\n\nprec_score = Precision()\nprec_score.update_state(y_pred_thresholded, y_test)\np = prec_score.result().numpy()\nprint('Precision Score = %.3f' % p)\n\nrecall_score = Recall()\nrecall_score.update_state(y_pred_thresholded, y_test)\nr = recall_score.result().numpy()\nprint('Recall Score = %.3f' % r)\n\nf1_score = 2*(p*r)/(p+r)\nprint('F1 Score = %.3f' % f1_score)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-12-10T21:07:09.628328Z","iopub.execute_input":"2024-12-10T21:07:09.628745Z","iopub.status.idle":"2024-12-10T21:07:09.773613Z","shell.execute_reply.started":"2024-12-10T21:07:09.628709Z","shell.execute_reply":"2024-12-10T21:07:09.772423Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a href=\"#ToC\" role=\"button\" aria-pressed=\"true\" >‚¨ÜÔ∏èBack to Table of Contents ‚¨ÜÔ∏è</a>","metadata":{}},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:15px; color:#159364; font-family:verdana;\">üí¨Thank you for reading! If you have any feedback or find anything wrong, please let me know!üôÇ</p></blockquote>","metadata":{}}]}